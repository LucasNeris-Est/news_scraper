"""Scraper espec√≠fico para o LinkedIn."""
from bs4 import BeautifulSoup
from typing import Dict
from datetime import datetime
import time
import re
from ..posts_scraper import PostsScraper


class LinkedInScraper(PostsScraper):
    """Scraper para posts do LinkedIn."""
    
    BASE_URL = "https://www.linkedin.com"
    
    def __init__(self, headless: bool = True, **kwargs):
        """Inicializa o LinkedInScraper com wait_until='networkidle'."""
        super().__init__(headless=headless, wait_until="networkidle", **kwargs)
    
    def extrair_dados_post(self, legenda: str) -> Dict[str, any]:
        """
        Extrai dados espec√≠ficos de um post do LinkedIn a partir da legenda capturada.
        
        Args:
            legenda: Texto completo capturado da p√°gina
        
        Returns:
            Dicion√°rio com autor, legenda_limpa, curtidas, data_post
        """
        print(f"üîç Extraindo dados espec√≠ficos do LinkedIn da legenda...")
        
        try:
            # Corta a legenda at√© encontrar trechos de interface do LinkedIn
            legenda_limpa = legenda
            if legenda_limpa:
                marcadores_fim = [
                    "Sign in to view more content",
                    "Join now",
                    "Sign in",
                    "Create your free account",
                    "Agree & Join",
                    "¬© 2025 LinkedIn",
                    "¬© 2024 LinkedIn",
                    "LinkedIn and third parties",
                ]
                
                for marcador in marcadores_fim:
                    if marcador in legenda_limpa:
                        legenda_limpa = legenda_limpa.split(marcador)[0].strip()
                        break
            
            # Extrai autor da primeira linha da legenda ou da URL
            autor = None
            if legenda_limpa:
                linhas = legenda_limpa.split('\n')
                for linha in linhas[:10]:  # Verifica as primeiras linhas
                    linha_limpa = linha.strip()
                    # Procura por padr√£o "Publica√ß√£o de Nome Sobrenome" ou "Nome Sobrenome" no in√≠cio
                    if linha_limpa.startswith("Publica√ß√£o de "):
                        autor = linha_limpa.replace("Publica√ß√£o de ", "").strip()
                        break
                    # Verifica se parece com um nome (tem espa√ßo, n√£o muito longo, n√£o √© menu)
                    if (linha_limpa and ' ' in linha_limpa and len(linha_limpa) < 50 and 
                        not linha_limpa.startswith('#') and 
                        linha_limpa not in ['Pular para conte√∫do principal', 'LinkedIn', 'Artigos', 'Pessoas', 'Learning', 'Vagas', 'Jogos']):
                        # Pode ser o nome do autor
                        autor = linha_limpa.replace('Verified', '').strip()
                        # Se encontrou algo que parece um nome, para
                        if autor and len(autor.split()) >= 2:  # Pelo menos 2 palavras (nome e sobrenome)
                            break
            
            # Extrai curtidas/likes da legenda
            curtidas = None
            if legenda_limpa:
                # Procura por padr√µes de curtidas/likes (formato: "110\n13 Comments\nLike")
                curtidas_patterns = [
                    r'\n(\d+(?:[,\.]\d+)*)\n\d+\s*Comments?\s*\nLike',  # Padr√£o LinkedIn: n√∫mero antes de "X Comments\nLike"
                    r'(\d+(?:[,\.]\d+)*)\s*reactions?',
                    r'(\d+(?:[,\.]\d+)*)\s*likes?',
                    r'(\d+(?:[,\.]\d+)*)\s*rea√ß√µes',
                    r'(\d+(?:[,\.]\d+)*)\s*curtidas?',
                ]
                
                for pattern in curtidas_patterns:
                    match = re.search(pattern, legenda_limpa, re.IGNORECASE)
                    if match:
                        try:
                            numero_str = match.group(1).replace(',', '').replace('.', '')
                            curtidas = int(numero_str)
                            break
                        except:
                            curtidas = match.group(1)
                            break
            
            # Extrai coment√°rios da legenda
            comentarios = None
            if legenda_limpa:
                # Procura por padr√µes de coment√°rios (formato: "13 Comments")
                comentarios_patterns = [
                    r'(\d+(?:[,\.]\d+)*)\s*Comments?',
                    r'(\d+(?:[,\.]\d+)*)\s*Coment√°rios?',
                    r'(\d+(?:[,\.]\d+)*)\s*Comment',
                ]
                
                for pattern in comentarios_patterns:
                    match = re.search(pattern, legenda_limpa, re.IGNORECASE)
                    if match:
                        try:
                            numero_str = match.group(1).replace(',', '').replace('.', '')
                            comentarios = int(numero_str)
                            break
                        except:
                            comentarios = match.group(1)
                            break
            
            # Extrai data de publica√ß√£o (formato relativo: 2d, 1w, 3h, etc)
            data_post = None
            if legenda_limpa:
                # Procura por padr√µes de tempo relativo
                data_patterns = [
                    r'(\d+[hdwmy])',  # 2d, 1w, 3h, 4m, 1y
                    r'(\d+\s*(?:hour|day|week|month|year)s?\s*ago)',
                    r'(\d+\s*(?:hora|dia|semana|m√™s|ano)s?\s*atr√°s)',
                ]
                
                for pattern in data_patterns:
                    match = re.search(pattern, legenda_limpa.lower())
                    if match:
                        data_post = match.group(1)
                        break
            
            dados = {
                "author": autor,
                "text": legenda_limpa,
                "likes": curtidas,
                "comments": comentarios,
                "date_post": data_post
            }
            
            print(f"‚úì Dados extra√≠dos:")
            print(f"   - Autor: {autor or 'N√£o encontrado'}")
            print(f"   - Legenda: {legenda_limpa[:50] + '...' if legenda_limpa and len(legenda_limpa) > 50 else legenda_limpa or 'N√£o encontrada'}")
            print(f"   - Curtidas: {curtidas or 'N√£o encontrado'}")
            print(f"   - Coment√°rios: {comentarios or 'N√£o encontrado'}")
            print(f"   - Data: {data_post or 'N√£o encontrada'}")
            
            return dados
            
        except Exception as e:
            print(f"‚úó Erro ao extrair dados: {e}")
            import traceback
            traceback.print_exc()
            return {
                "autor": None,
                "legenda": "",
                "curtidas": None,
                "comentarios": None,
                "data_post": None
            }
    
    def processar_post(self, url: str, arquivo_saida: str = "post_linkedin.json") -> Dict:
        """
        Processa um post completo do LinkedIn: captura texto e extrai dados.
        
        Args:
            url: URL do post do LinkedIn
            arquivo_saida: Nome do arquivo JSON de sa√≠da (timestamp ser√° adicionado automaticamente)
        
        Returns:
            Dicion√°rio com todos os dados do post
        """
        print(f"\n{'='*60}")
        print(f"üíº PROCESSANDO POST DO LINKEDIN")
        print(f"{'='*60}\n")
        
        # Extrai autor da URL (formato: /posts/nome-sobrenome-id_...)
        autor_url = None
        match_url = re.search(r'/posts/([^_/]+)', url)
        if match_url:
            # Converte h√≠fens em espa√ßos e capitaliza cada palavra
            autor_slug = match_url.group(1)
            # Remove n√∫meros no final do slug (ex: gustavo-pires-3baa60163 -> gustavo-pires)
            autor_slug = re.sub(r'-[\da-f]+$', '', autor_slug)
            # Converte para nome leg√≠vel
            autor_url = ' '.join(word.capitalize() for word in autor_slug.split('-'))
            print(f"üìù Autor extra√≠do da URL: {autor_url}")
        
        # Adiciona timestamp ao nome do arquivo
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        nome_base, extensao = arquivo_saida.rsplit('.', 1) if '.' in arquivo_saida else (arquivo_saida, 'json')
        arquivo_com_timestamp = f"{nome_base}_{timestamp}.{extensao}"
        
        # 1. Captura o texto completo da p√°gina
        texto_completo = self.capturar_texto_rede_social(url)
        
        # 2. Extrai dados espec√≠ficos do LinkedIn a partir do texto capturado
        dados_especificos = self.extrair_dados_post(texto_completo)
        
        # 3. Usa o autor da URL se n√£o foi encontrado no texto
        autor_final = autor_url
        
        # 4. Salva tudo em JSON (inclui comentarios nos dados adicionais)
        resultado = self.salvar_json(
            texto_capturado=texto_completo,
            url=url,
            legenda=dados_especificos.get("text", ""),
            curtidas=dados_especificos.get("likes"),
            data_post=dados_especificos.get("date_post"),
            autor=autor_final,
            arquivo=arquivo_com_timestamp,
            comentarios=dados_especificos.get("comments"),
            social_network="linkedin"
        )
        
        print(f"\n{'='*60}")
        print(f"‚úÖ PROCESSAMENTO CONCLU√çDO")
        print(f"{'='*60}\n")
        
        return resultado
